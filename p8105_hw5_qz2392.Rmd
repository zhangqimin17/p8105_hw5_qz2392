---
title: "p8105_hw5_qz2392"
author: "Qimin Zhang"
date: "11/2/2019"
output: 
  github_document:
    pandoc_args: --webtex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Problem 1
```{r}
library(tidyverse)

set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species)) %>% 
  janitor::clean_names()
```
Write funtion to fill in the missing values.
```{r}
fill_missing = function(x){
  if (is.numeric(x)){
    x = ifelse(is.na(x), mean(x, na.rm = T), x)
  }
  if (is.character(x)){
    x = ifelse(is.na(x), "virginica", x)
  }
  return(x)
}

iris_with_missing = 
  iris_with_missing %>% 
  map_df(~ fill_missing(.x))
```

# Problem 2
```{r message=FALSE, warning=FALSE}
data = tibble(
  file_name = list.files(".", pattern = "*.csv")
)

data$data =
list.files(".", pattern = "*.csv") %>% 
  map(read_csv)
```

```{r message=FALSE, warning=FALSE}
data =
  data %>% 
  unnest() %>% 
  mutate(
    type = case_when(
      file_name %>% str_detect("con") ~ "control",
      file_name %>% str_detect("exp") ~ "experiment",
    ),
    id = file_name %>% str_extract_all("[0-9]+") %>% as.numeric()
  ) %>% 
  select(type, id, everything(), -file_name)
```

```{r}
data %>%
  pivot_longer(
    week_1:week_8,
    names_to = "week"
  ) %>% 
  mutate(
    type_id = paste(type, "_", as.character(id), sep = "")
  ) %>% 
  ggplot(aes(x = week, y = value, group = type_id, color = type)) +
  geom_line() +
  labs(
    title = "Value changes through weeks across groups"
  )
```

The values of experiment group are generally higher than that of control group.

# Problem 3

```{r}
sim_regression = function(n = 30, beta0 = 2, beta1) {
  
  sim_data = tibble(
    x = rnorm(n, mean = 1, sd = 1),
    y = beta0 + beta1 * x + rnorm(n, 0, sqrt(50))
  )
  
  ls_fit = lm(y ~ x, data = sim_data) %>% 
    broom::tidy()
  
  tibble(
    beta1_hat = ls_fit[[2]][[2]],
    p_value = ls_fit[[5]][[2]]
  )
}

sim_regression_repeat = function(beta1){

  output = vector("list", 10000)

  for (i in 1:10000) {
  output[[i]] = sim_regression(n = 30, beta0 = 2, beta1)
  }

  sim_results = bind_rows(output)

  return(sim_results)
}
```

```{r}
sim = tibble(
  beta1 = 0:6
) 

sim$data = 
  sim %>% pull(beta1) %>% map(sim_regression_repeat)
```

```{r message=FALSE, warning=FALSE}
sim %>% 
  unnest() %>% 
  mutate(
    reject = ifelse(p_value < 0.05, 1, 0)
  ) %>%
  group_by(beta1) %>% 
  summarize(
    power = length(reject[reject == 1])/length(reject)
  ) %>% 
  ggplot(aes(x = beta1, y = power)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Power VS True beta 1"
  )
```

From the plot above we can see that as effect size increase, the power increase.

```{r message=FALSE, warning=FALSE}
sim %>% 
  unnest() %>%
  mutate(
    type = 'All samples'
  ) %>% 
  group_by(beta1) %>% 
  mutate(
    mean_beta1_hat = mean(beta1_hat)
  ) %>% 
  bind_rows(
  sim %>% 
  unnest() %>%
  filter(p_value < 0.05) %>%
  mutate(
    type = 'Null rejected samples'
  ) %>%  
  group_by(beta1) %>% 
  mutate(
    mean_beta1_hat = mean(beta1_hat)
  )) %>% 
  ggplot(aes(x = beta1, y = mean_beta1_hat, color = type)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Mean beta 1 hat VS True beta 1"
  )
```

The sample average of $\hat\beta_1$ across tests for which the null is rejected is not approximately equal to the true value of $\beta_1$. Because 
the location of samples with null rejected are farther from that of the null.